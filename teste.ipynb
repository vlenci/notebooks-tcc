{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate lenci_enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8090ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import surprise\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    rmse,\n",
    "    mae,\n",
    "    rsquared,\n",
    "    exp_var,\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    get_top_k_items,\n",
    ")\n",
    "from recommenders.models.surprise.surprise_utils import (\n",
    "    predict,\n",
    "    compute_ranking_predictions,\n",
    ")\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Surprise version: {surprise.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4ea92ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       1       17     4.0\n",
      "1       1       25     1.0\n",
      "2       1       29     2.0\n",
      "3       1       30     5.0\n",
      "4       1       32     5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Caminho do arquivo local do MovieLens 100k\n",
    "file_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-32m\\\\ratings.csv\"  # ajuste para onde você extraiu o dataset\n",
    "\n",
    "# Ler o arquivo com pandas\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "# Selecionar apenas as colunas necessárias\n",
    "df = df[[\"userId\", \"movieId\", \"rating\"]]\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(df.head())\n",
    "\n",
    "# Criar Dataset do Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df, reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5392c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "\n",
    "# 1️⃣ Dividir os dados em treino e teste (75% treino, 25% teste)\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# 2️⃣ Criar o modelo SVD\n",
    "svd = SVD(\n",
    "    n_factors=200,   # dimensão dos vetores latentes\n",
    "    n_epochs=30,     # número de iterações do SGD\n",
    "    random_state=42,\n",
    "    verbose=True     # imprime progresso do treino\n",
    ")\n",
    "\n",
    "# 3️⃣ Treinar o modelo\n",
    "svd.fit(trainset)\n",
    "\n",
    "# 4️⃣ Fazer previsões no conjunto de teste\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# 5️⃣ Avaliar o modelo usando RMSE e MAE\n",
    "rmse_val = accuracy.rmse(predictions)\n",
    "mae_val = accuracy.mae(predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse_val}\")\n",
    "print(f\"MAE: {mae_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Função auxiliar para pegar os Top-K itens recomendados\n",
    "def get_top_n(predictions, n=10):\n",
    "    # Dicionário para armazenar as recomendações por usuário\n",
    "    user_recommendations = defaultdict(list)\n",
    "\n",
    "    # Organiza as previsões por usuário\n",
    "    for user_id, movie_id, true_rating, predicted_rating, _ in predictions:\n",
    "        user_recommendations[user_id].append((movie_id, predicted_rating))\n",
    "\n",
    "    # Ordena as predições por nota estimada e pega o Top-N\n",
    "    for user_id, movie_ratings in user_recommendations.items():\n",
    "        movie_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        user_recommendations[user_id] = movie_ratings[:n]\n",
    "\n",
    "    return user_recommendations\n",
    "\n",
    "\n",
    "# ⚡ Fazer previsões em todos os pares usuário-filme que não estavam no treino\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Gera previsões para todos os pares usuário-filme não vistos no treino\n",
    "all_predictions = svd.test(trainset.build_anti_testset())\n",
    "\n",
    "# Pega as top-10 recomendações para cada usuário\n",
    "top_recommendations = get_top_n(all_predictions, n=10)\n",
    "\n",
    "# Exibir recomendações para os 5 primeiros usuários\n",
    "for user_id, recommended_movies in list(top_recommendations.items())[:5]:\n",
    "    print(f\"\\nUsuário {user_id} - Recomendações:\")\n",
    "    for movie_id, predicted_rating in recommended_movies:\n",
    "        print(f\"  Filme {movie_id} com nota estimada {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8daccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fede259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1. Carregar dataset =========\n",
    "file_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\ratings.csv\"\n",
    "movies_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\movies.csv\"  # precisa desse para títulos\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "movies = pd.read_csv(movies_path, sep=\",\")\n",
    "\n",
    "# Vamos trabalhar só com as colunas necessárias\n",
    "df = df[[\"userId\", \"movieId\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e42e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responda 0 (não assistiu), 1 (não gostou), 2 (gostou).\n",
      "Após 10 avaliações válidas (1 ou 2), vamos treinar o modelo.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Coletamos 10 avaliações válidas do usuário!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========= 2. Simulação de avaliações do usuário =========\n",
    "import numpy as np\n",
    "\n",
    "avaliacoes_usuario = []  # guarda (userId, movieId, rating)\n",
    "print(\"Responda 0 (não assistiu), 1 (não gostou), 2 (gostou).\")\n",
    "print(\"Após 10 avaliações válidas (1 ou 2), vamos treinar o modelo.\\n\")\n",
    "\n",
    "# Embaralhar os filmes e calcular peso por popularidade\n",
    "movie_counts = movies.groupby(\"movieId\").size()\n",
    "movies[\"weight\"] = movies[\"movieId\"].map(movie_counts)\n",
    "\n",
    "contador_validas = 0\n",
    "movies_restantes = movies.copy()\n",
    "\n",
    "while contador_validas < 10 and len(movies_restantes) > 0:\n",
    "    # Seleciona filme aleatório ponderado\n",
    "    filme = movies_restantes.sample(n=1, weights=\"weight\").iloc[0]\n",
    "    movie_id = filme[\"movieId\"]\n",
    "    title = filme[\"title\"]\n",
    "\n",
    "    resposta = input(f\"Você assistiu '{title}'? (0=Não, 1=Não gostou, 2=Gostou): \")\n",
    "\n",
    "    if resposta not in [\"0\", \"1\", \"2\"]:\n",
    "        print(\"Resposta inválida, tente novamente.\")\n",
    "        continue\n",
    "\n",
    "    resposta = int(resposta)\n",
    "\n",
    "    if resposta in [1, 2]:\n",
    "        avaliacoes_usuario.append((9999, movie_id, resposta))  # userId fixo=9999\n",
    "        contador_validas += 1\n",
    "\n",
    "    # Remove o filme da lista para não aparecer novamente\n",
    "    movies_restantes = movies_restantes[movies_restantes[\"movieId\"] != movie_id]\n",
    "\n",
    "print(\"\\n✅ Coletamos 10 avaliações válidas do usuário!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e38f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 3. Preparar dataset para Surprise =========\n",
    "# Criar novo DF juntando dataset original + usuário novo\n",
    "df_usuario = pd.DataFrame(avaliacoes_usuario, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "df_final = pd.concat([df, df_usuario], ignore_index=True)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_final[[\"userId\", \"movieId\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fc4078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x16b5043e520>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 4. Treinar modelo =========\n",
    "trainset = data.build_full_trainset()\n",
    "svd = SVD(n_factors=1000, n_epochs=30, random_state=42, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9299fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎬 Recomendações para você:\n",
      "- Upside Down: The Creation Records Story (2010) (nota estimada 4.24)\n",
      "- Blue Velvet (1986) (nota estimada 4.20)\n",
      "- Three Billboards Outside Ebbing, Missouri (2017) (nota estimada 4.15)\n",
      "- Once Upon a Time in the West (C'era una volta il West) (1968) (nota estimada 4.15)\n",
      "- Uncle Buck (1989) (nota estimada 4.10)\n",
      "- Reservoir Dogs (1992) (nota estimada 4.10)\n",
      "- Eyes of Tammy Faye, The (2000) (nota estimada 4.09)\n",
      "- Chaser, The (Chugyeogja) (2008) (nota estimada 4.05)\n",
      "- Call Me by Your Name (2017) (nota estimada 4.04)\n",
      "- Ogre, The (Unhold, Der) (1996) (nota estimada 4.03)\n"
     ]
    }
   ],
   "source": [
    "# ========= 5. Gerar recomendações =========\n",
    "# Criar anti-testset só para o usuário novo\n",
    "anti_testset = []\n",
    "for movie_id in movies[\"movieId\"]:\n",
    "    if movie_id not in df_usuario[\"movieId\"].values:  # só filmes não avaliados\n",
    "        anti_testset.append((9999, movie_id, 0))  # rating dummy\n",
    "\n",
    "predictions = svd.test(anti_testset)\n",
    "\n",
    "# Ordenar por nota estimada\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Pegar top 10\n",
    "top_10 = predictions[:10]\n",
    "\n",
    "print(\"\\n🎬 Recomendações para você:\")\n",
    "for pred in top_10:\n",
    "    movie_id = pred.iid\n",
    "    title = movies[movies[\"movieId\"] == int(movie_id)][\"title\"].values[0]\n",
    "    print(f\"- {title} (nota estimada {pred.est:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenci_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
