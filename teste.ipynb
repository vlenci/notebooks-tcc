{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate lenci_enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import surprise\n",
    "from surprise import SVD, Reader\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    ")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d75e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 1. Preparar dataset ===================\n",
    "file_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\ratings.csv\"\n",
    "movies_file = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\movies.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[[\"userId\", \"movieId\", \"rating\"]]\n",
    "# Padronizar nomes de colunas para Recommenders\n",
    "df = df.rename(columns={\"userId\": \"userID\", \"movieId\": \"itemID\", \"rating\": \"rating\"})\n",
    "\n",
    "movies = pd.read_csv(movies_file)\n",
    "movies = movies.rename(columns={\"movieId\": \"itemID\", \"title\": \"title\"})\n",
    "# movies = movies.merge(df.groupby(\"itemID\").size().reset_index(name=\"num_ratings\"), on=\"itemID\")\n",
    "# movies = movies.sort_values(\"num_ratings\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 2. Criar treino/teste ===================\n",
    "\n",
    "# A seed √© o que faz a base de treino/teste sempre ser a mesma.\n",
    "train_df, test_df = python_random_split(df, 0.8, seed=42)\n",
    "\n",
    "# Criar dataset do Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Adaptar DataFrame 'train_df' para ser utilizado na fun√ß√£o 'SVD'\n",
    "trainset = surprise.Dataset.load_from_df(train_df, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 3. Treinar SVD ===================\n",
    "svd = SVD(n_factors=200, n_epochs=30, random_state=42, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 4. Criar predi√ß√µes  ===================\n",
    "predictions = predict(svd, test_df, usercol=\"userID\", itemcol=\"itemID\")\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca54b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √â utilizado para avaliar as m√©tricas de ranking (MAP, NDCG, Precision@K, Recall@K).\n",
    "\n",
    "all_predictions = compute_ranking_predictions(\n",
    "    svd, train_df, usercol=\"userID\", itemcol=\"itemID\", remove_seen=True\n",
    ")\n",
    "all_predictions.head()\n",
    "\n",
    "# No bloco de c√≥digo seguinte √© feito uma compara√ß√£o entre as predi√ß√µes e as notas reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd42a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a base de dados t√° realmente randomizando a cada vez que roda, j√° que o resultado √© sempre o mesmo.\n",
    "\n",
    "# ‚ÄúO modelo acerta a nota que o usu√°rio deu para o filme?‚Äù\n",
    "eval_rmse = rmse(test_df, predictions)\n",
    "eval_mae = mae(test_df, predictions)\n",
    "eval_rsquared = rsquared(test_df, predictions)\n",
    "eval_exp_var = exp_var(test_df, predictions)\n",
    "\n",
    "# O modelo est√° colocando os filmes certos (que o usu√°rio realmente gosta) nas primeiras posi√ß√µes das recomenda√ß√µes?\n",
    "eval_map = map_at_k(test_df, all_predictions, col_prediction=\"prediction\", k=10)\n",
    "eval_ndcg = ndcg_at_k(test_df, all_predictions, col_prediction=\"prediction\", k=10)\n",
    "eval_precision = precision_at_k(\n",
    "    test_df, all_predictions, col_prediction=\"prediction\", k=10\n",
    ")\n",
    "eval_recall = recall_at_k(test_df, all_predictions, col_prediction=\"prediction\", k=10)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "    \"MAE:\\t\\t%f\" % eval_mae,\n",
    "    \"rsquared:\\t%f\" % eval_rsquared,\n",
    "    \"exp var:\\t%f\" % eval_exp_var,\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "print(\n",
    "    \"MAP:\\t\\t%f\" % eval_map,\n",
    "    \"NDCG:\\t\\t%f\" % eval_ndcg,\n",
    "    \"Precision@K:\\t%f\" % eval_precision,\n",
    "    \"Recall@K:\\t%f\" % eval_recall,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123941e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 5. Recomenda√ß√£o para usu√°rio final ===================\n",
    "# Exemplo: usu√°rio final com userID = 4\n",
    "user_id = 4\n",
    "\n",
    "# Obter todas as avalia√ß√µes desse usu√°rio no dataset\n",
    "user_ratings = df[df[\"userID\"] == user_id]\n",
    "\n",
    "# Conjunto de filmes que o usu√°rio j√° avaliou\n",
    "user_movies = set(user_ratings[\"itemID\"])\n",
    "\n",
    "# Todos os filmes do dataset\n",
    "all_movies = set(df[\"itemID\"])\n",
    "\n",
    "# Filmes que o usu√°rio ainda n√£o avaliou\n",
    "movies_to_predict = list(all_movies - user_movies)\n",
    "\n",
    "# Criar anti-testset para esse usu√°rio\n",
    "anti_testset_user = [(user_id, iid, 0) for iid in movies_to_predict]  # 0 √© placeholder\n",
    "\n",
    "print(anti_testset_user)\n",
    "\n",
    "# Fazer predi√ß√£o das notas\n",
    "predictions_user = svd.test(anti_testset_user)\n",
    "\n",
    "print(predictions_user)\n",
    "\n",
    "# Fun√ß√£o para pegar Top-N recomenda√ß√µes\n",
    "def get_top_n(predictions, n=10):\n",
    "    from collections import defaultdict\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid in top_n:\n",
    "        top_n[uid].sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = top_n[uid][:n]\n",
    "    return top_n\n",
    "\n",
    "top_recommendations = get_top_n(predictions_user, n=10)\n",
    "\n",
    "# Exibir recomenda√ß√µes\n",
    "print(\"\\nüé¨ Top 10 filmes recomendados para o usu√°rio %d:\" % user_id)\n",
    "for item_id, pred_rating in top_recommendations[user_id]:\n",
    "    title = movies[movies[\"itemID\"] == item_id][\"title\"].values[0]\n",
    "    print(f\"{title} (nota estimada: {pred_rating:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e399494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de 'all_predictions' para o usu√°rio 4\n",
    "df_user1 = pd.DataFrame(all_predictions)\n",
    "res = df_user1[df_user1[\"userID\"] == 4].sort_values(by=\"prediction\", ascending=False)\n",
    "\n",
    "# Adicionar o t√≠tulo do filme\n",
    "res = res.merge(movies[[\"itemID\", \"title\"]], on=\"itemID\", how=\"left\")\n",
    "\n",
    "# Mostrar os top 50\n",
    "res.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2268c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 6. Simula√ß√£o de novo usu√°rio ===================\n",
    "from collections import defaultdict\n",
    "\n",
    "# Definir o ID do novo usu√°rio (n√£o presente no dataset original)\n",
    "novo_user_id = df[\"userID\"].max() + 5  # por exemplo, 610\n",
    "\n",
    "# Mostrar filmes populares para o usu√°rio avaliar (pode ajustar crit√©rio de sele√ß√£o)\n",
    "# Selecionar filmes aleat√≥rios ou os mais populares\n",
    "avaliacoes_usuario = []\n",
    "MAX_AVALIACOES = 20\n",
    "contador = 0\n",
    "\n",
    "print(f\"\\nüìù Novo usu√°rio ({novo_user_id}) vai avaliar {MAX_AVALIACOES} filmes.\\n\")\n",
    "\n",
    "for _, row in movies.sample(frac=1).iterrows():  # mistura os filmes\n",
    "    if contador >= MAX_AVALIACOES:\n",
    "        break\n",
    "    \n",
    "    movie_id = row[\"itemID\"]\n",
    "    title = row[\"title\"]\n",
    "    # Pega apenas o primeiro g√™nero\n",
    "    first_genre = row[\"genres\"].split(\"|\")[0] if \"genres\" in row else \"Desconhecido\"\n",
    "    \n",
    "    resposta = input(f\"Voc√™ assistiu '{title}' (G√™nero: {first_genre})? Nota 1-5 (0=N√£o assistiu): \")\n",
    "    \n",
    "    try:\n",
    "        nota = int(resposta)\n",
    "        if nota == 0:\n",
    "            continue  # usu√°rio n√£o assistiu, ignora\n",
    "        if nota < 1 or nota > 5:\n",
    "            print(\"Nota inv√°lida, use 1-5.\")\n",
    "            continue\n",
    "    except:\n",
    "        print(\"Resposta inv√°lida, tente novamente.\")\n",
    "        continue\n",
    "    \n",
    "    avaliacoes_usuario.append((novo_user_id, movie_id, nota))\n",
    "    contador += 1\n",
    "\n",
    "print(f\"\\n‚úÖ Coletadas {len(avaliacoes_usuario)} avalia√ß√µes do novo usu√°rio.\\n\")\n",
    "\n",
    "# Criar DataFrame tempor√°rio com avalia√ß√µes do novo usu√°rio\n",
    "df_novo_usuario = pd.DataFrame(avaliacoes_usuario, columns=[\"userID\", \"itemID\", \"rating\"])\n",
    "\n",
    "# Construir anti-testset apenas para os filmes que o usu√°rio ainda n√£o avaliou\n",
    "user_movies = set(df_novo_usuario[\"itemID\"])\n",
    "all_movies = set(df[\"itemID\"])\n",
    "movies_to_predict = list(all_movies - user_movies)\n",
    "\n",
    "anti_testset_user = [(novo_user_id, iid, 0) for iid in movies_to_predict]\n",
    "\n",
    "# Predi√ß√£o SVD para o novo usu√°rio\n",
    "predicoes_novo_usuario = svd.test(anti_testset_user)\n",
    "\n",
    "# Fun√ß√£o para pegar top-N recomenda√ß√µes\n",
    "def get_top_n(predictions, n=10):\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "    for uid in top_n:\n",
    "        top_n[uid].sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = top_n[uid][:n]\n",
    "    return top_n\n",
    "\n",
    "top_recommendations = get_top_n(predicoes_novo_usuario, n=10)\n",
    "\n",
    "# Mostrar resultados com t√≠tulo e primeiro g√™nero\n",
    "print(f\"\\nüé¨ Top 10 recomenda√ß√µes para o usu√°rio {novo_user_id}:\")\n",
    "for item_id, pred_rating in top_recommendations[novo_user_id]:\n",
    "    title = movies[movies[\"itemID\"] == item_id][\"title\"].values[0]\n",
    "    first_genre = movies[movies[\"itemID\"] == item_id][\"genres\"].values[0].split(\"|\")[0]\n",
    "    print(f\"{title} (G√™nero: {first_genre}, nota estimada: {pred_rating:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f5ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 7. Fold-in corrigido: s√≥ mostrar filmes do trainset e evitar fallback desnecess√°rio ====\n",
    "import numpy as np\n",
    "\n",
    "MAX_AVALIACOES_NOVO = 20\n",
    "MIN_AVALIACOES_PARA_FOLDIN = 5   # voc√™ pode ajustar\n",
    "LAMBDA_REG = 0.1\n",
    "TOP_K = 10\n",
    "\n",
    "novo_user_id = int(df[\"userID\"].max()) + 1\n",
    "print(f\"\\n=== Fold-in: novo usu√°rio {novo_user_id} ===\")\n",
    "print(f\"Iremos coletar at√© {MAX_AVALIACOES_NOVO} avalia√ß√µes (1-5). Responda 0 se n√£o assistiu.)\\n\")\n",
    "\n",
    "# --- 1) Encontrar os raw item IDs que aparecem no trainset (raw ids como strings) ---\n",
    "train_raw_ids = [trainset.to_raw_iid(i) for i in range(trainset.n_items)]\n",
    "# Filtrar o DataFrame de filmes para conter apenas itens presentes no trainset\n",
    "movies_in_train = movies[movies[\"itemID\"].astype(str).isin(train_raw_ids)].copy()\n",
    "\n",
    "if movies_in_train.empty:\n",
    "    raise RuntimeError(\"Nenhum filme do DataFrame de filmes foi encontrado no trainset. Verifique os IDs.\")\n",
    "\n",
    "# amostrar filmes a mostrar ao usu√°rio (embaralha com random_state para reprodutibilidade)\n",
    "movies_to_show = movies_in_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "avaliacoes = []\n",
    "contador = 0\n",
    "\n",
    "for _, row in movies_to_show.iterrows():\n",
    "    if contador >= MAX_AVALIACOES_NOVO:\n",
    "        break\n",
    "    raw_iid = str(row[\"itemID\"])  # usar string para compatibilidade com trainset mappings\n",
    "    title = row[\"title\"]\n",
    "    first_genre = row[\"genres\"].split(\"|\")[0] if \"genres\" in row and isinstance(row[\"genres\"], str) else \"Desconhecido\"\n",
    "\n",
    "    resposta = input(f\"Nota para '{title}' (G√™nero: {first_genre}) [1-5] (0 = n√£o assisti): \")\n",
    "    try:\n",
    "        nota = int(resposta)\n",
    "    except:\n",
    "        print(\"Entrada inv√°lida, tente novamente.\")\n",
    "        continue\n",
    "    if nota == 0:\n",
    "        continue\n",
    "    if nota < 1 or nota > 5:\n",
    "        print(\"Nota inv√°lida, use 1-5.\")\n",
    "        continue\n",
    "\n",
    "    # aqui garantimos que o raw_iid est√° no trainset, pois movies_to_show foi filtrado\n",
    "    avaliacoes.append((raw_iid, float(nota)))\n",
    "    contador += 1\n",
    "\n",
    "print(f\"\\nColetadas {len(avaliacoes)} avalia√ß√µes do novo usu√°rio.\\n\")\n",
    "\n",
    "# Mapear avalia√ß√µes para inner ids (agora n√£o deve lan√ßar erro, pois filtramos)\n",
    "inner_ids = []\n",
    "ratings = []\n",
    "for raw_iid, r in avaliacoes:\n",
    "    try:\n",
    "        inner = trainset.to_inner_iid(raw_iid)\n",
    "    except ValueError:\n",
    "        # safety: deveria n√£o acontecer, porque filtramos, mas apenas no caso improv√°vel, pular\n",
    "        continue\n",
    "    inner_ids.append(inner)\n",
    "    ratings.append(r)\n",
    "\n",
    "# Se ainda assim avalia√ß√µes v√°lidas forem poucas, avisar e usar fallback (apenas aviso)\n",
    "if len(inner_ids) < MIN_AVALIACOES_PARA_FOLDIN:\n",
    "    print(\"Avalia√ß√µes v√°lidas insuficientes para fold-in (usu√°rio avaliou poucos filmes ou cancelou).\")\n",
    "    print(\"Considere pedir mais avalia√ß√µes ou usar fallback por popularidade.\\n\")\n",
    "    # aqui apenas mostramos um fallback por popularidade (pode manter / customizar)\n",
    "    pop = df.groupby(\"itemID\").size().reset_index(name=\"num_ratings\")\n",
    "    pop = pop.merge(movies[[\"itemID\", \"title\", \"genres\"]], on=\"itemID\", how=\"left\")\n",
    "    pop = pop.sort_values(\"num_ratings\", ascending=False).head(TOP_K)\n",
    "    print(\"Top por popularidade (fallback):\")\n",
    "    for _, row in pop.iterrows():\n",
    "        first_genre = row[\"genres\"].split(\"|\")[0] if isinstance(row.get(\"genres\", None), str) else \"Desconhecido\"\n",
    "        print(f\"{row['title']} (G√™nero: {first_genre})\")\n",
    "else:\n",
    "    # construir Q e y (res√≠duos)\n",
    "    mu = trainset.global_mean\n",
    "    k = svd.n_factors\n",
    "    Q = np.array([svd.qi[i] for i in inner_ids])     # shape (m, k)\n",
    "    bi = np.array([svd.bi[i] for i in inner_ids])    # item biases for rated items\n",
    "    y = np.array(ratings) - mu - bi                  # residuals\n",
    "\n",
    "    # resolver (Q^T Q + lambda I) p_u = Q^T y\n",
    "    A = Q.T.dot(Q) + LAMBDA_REG * np.eye(k)\n",
    "    b = Q.T.dot(y)\n",
    "    try:\n",
    "        p_u = np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        p_u = np.linalg.pinv(A).dot(b)\n",
    "\n",
    "    # estimar bias do usu√°rio\n",
    "    residuals = y - Q.dot(p_u)\n",
    "    b_u = float(np.mean(residuals)) if residuals.size > 0 else 0.0\n",
    "\n",
    "    # predi√ß√£o para todos os items do trainset\n",
    "    preds = []\n",
    "    for inner_j in range(trainset.n_items):\n",
    "        qj = svd.qi[inner_j]\n",
    "        bj = svd.bi[inner_j]\n",
    "        est = mu + bj + b_u + p_u.dot(qj)\n",
    "        raw_j = trainset.to_raw_iid(inner_j)  # string\n",
    "        preds.append((raw_j, est))\n",
    "\n",
    "    # remover itens que o usu√°rio j√° avaliou (raw ids strings)\n",
    "    avaliados_raw = set([raw for raw, _ in avaliacoes])\n",
    "    preds = [p for p in preds if p[0] not in avaliados_raw]\n",
    "\n",
    "    # ordenar e pegar top K\n",
    "    preds.sort(key=lambda x: x[1], reverse=True)\n",
    "    topk = preds[:TOP_K]\n",
    "\n",
    "    # exibir resultados com t√≠tulo e primeiro g√™nero\n",
    "    print(f\"\\nüé¨ Top-{TOP_K} recomenda√ß√µes para o novo usu√°rio (fold-in):\\n\")\n",
    "    for raw_j, est in topk:\n",
    "        # raw_j √© string, casar com movies.itemID convertendo tamb√©m para string\n",
    "        row = movies[movies[\"itemID\"].astype(str) == raw_j]\n",
    "        if not row.empty:\n",
    "            title = row.iloc[0][\"title\"]\n",
    "            genres = row.iloc[0][\"genres\"] if \"genres\" in row.columns else \"\"\n",
    "            first_genre = genres.split(\"|\")[0] if isinstance(genres, str) and genres else \"Desconhecido\"\n",
    "            print(f\"{title} (G√™nero: {first_genre}) ‚Äî nota estimada: {est:.2f}\")\n",
    "        else:\n",
    "            print(f\"{raw_j} ‚Äî nota estimada: {est:.2f}\")\n",
    "\n",
    "print(\"\\n(Fim do fold-in)\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenci_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
