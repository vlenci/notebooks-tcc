{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate lenci_enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8e794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import surprise\n",
    "from surprise import SVD, Reader\n",
    "from recommenders.models.surprise.surprise_utils import predict, compute_ranking_predictions\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    ")\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85d75e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== 1. Preparar dataset ===================\n",
    "\n",
    "file_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\ratings.csv\"\n",
    "movies_file = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\movies.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df[[\"userId\", \"movieId\", \"rating\"]]\n",
    "# Padronizar nomes de colunas para Recommenders\n",
    "df = df.rename(columns={\"userId\": \"userID\", \"movieId\": \"itemID\", \"rating\": \"rating\"})\n",
    "\n",
    "movies = pd.read_csv(movies_file)\n",
    "movies = movies.rename(columns={\"movieId\": \"itemID\", \"title\": \"title\"})\n",
    "# movies = movies.merge(df.groupby(\"itemID\").size().reset_index(name=\"num_ratings\"), on=\"itemID\")\n",
    "# movies = movies.sort_values(\"num_ratings\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1608ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usu√°rios com mais avalia√ß√µes (candidatos para holdout):\n",
      "     userID  num_ratings\n",
      "413     414         2698\n",
      "598     599         2478\n",
      "473     474         2108\n",
      "447     448         1864\n",
      "273     274         1346\n",
      "609     610         1302\n",
      "67       68         1260\n",
      "379     380         1218\n",
      "605     606         1115\n",
      "287     288         1055\n",
      "\n",
      "‚úì Usu√°rio selecionado para holdout (fold-in): 249\n",
      "  Este usu√°rio N√ÉO participar√° do treinamento.\n",
      "\n",
      "Dataset original: 100836 avalia√ß√µes\n",
      "Avalia√ß√µes do usu√°rio holdout: 1046\n",
      "Dataset para treinamento (sem holdout): 99790 avalia√ß√µes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =================== 2. Selecionar usu√°rio holdout ===================\n",
    "\n",
    "# --- Selecionar um usu√°rio para teste de fold-in (ser√° removido do treinamento) ---\n",
    "user_counts = df.groupby(\"userID\").size().reset_index(name=\"num_ratings\")\n",
    "user_counts = user_counts[user_counts[\"num_ratings\"] >= 20].sort_values(\"num_ratings\", ascending=False)\n",
    "\n",
    "print(\"Usu√°rios com mais avalia√ß√µes (candidatos para holdout):\")\n",
    "print(user_counts.head(10))\n",
    "print()\n",
    "\n",
    "# Voc√™ pode escolher manualmente ou pegar automaticamente\n",
    "HOLDOUT_USER_ID = int(user_counts.iloc[10][\"userID\"])  # Pega o 6¬∫ usu√°rio com mais avalia√ß√µes\n",
    "# Ou defina manualmente: HOLDOUT_USER_ID = 4\n",
    "\n",
    "print(f\"‚úì Usu√°rio selecionado para holdout (fold-in): {HOLDOUT_USER_ID}\")\n",
    "print(f\"  Este usu√°rio N√ÉO participar√° do treinamento.\\n\")\n",
    "\n",
    "# Separar dados do usu√°rio holdout\n",
    "user_holdout_data = df[df[\"userID\"] == HOLDOUT_USER_ID].copy()\n",
    "df_sem_holdout = df[df[\"userID\"] != HOLDOUT_USER_ID].copy()\n",
    "\n",
    "print(f\"Dataset original: {len(df)} avalia√ß√µes\")\n",
    "print(f\"Avalia√ß√µes do usu√°rio holdout: {len(user_holdout_data)}\")\n",
    "print(f\"Dataset para treinamento (sem holdout): {len(df_sem_holdout)} avalia√ß√µes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4216b833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 79832 avalia√ß√µes\n",
      "Test set: 19958 avalia√ß√µes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =================== 4. Criar treino/teste (sem o usu√°rio holdout)===================\n",
    "\n",
    "# A seed √© o que faz a base de treino/teste sempre ser a mesma.\n",
    "train_df, test_df = python_random_split(df_sem_holdout, 0.8, seed=42)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} avalia√ß√µes\")\n",
    "print(f\"Test set: {len(test_df)} avalia√ß√µes\\n\")\n",
    "\n",
    "# Criar dataset do Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Adaptar DataFrame 'train_df' para ser utilizado na fun√ß√£o 'SVD'\n",
    "trainset = surprise.Dataset.load_from_df(train_df, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c12f842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1fb45017220>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =================== 5. Treinar SVD ===================\n",
    "svd = SVD(n_factors=200, n_epochs=30, random_state=42, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fae9f31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>923</td>\n",
       "      <td>3.167365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>434</td>\n",
       "      <td>292</td>\n",
       "      <td>3.434771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>396</td>\n",
       "      <td>783</td>\n",
       "      <td>3.177512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>399</td>\n",
       "      <td>2959</td>\n",
       "      <td>4.057186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>543</td>\n",
       "      <td>2.871088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "0      68     923    3.167365\n",
       "1     434     292    3.434771\n",
       "2     396     783    3.177512\n",
       "3     399    2959    4.057186\n",
       "4     500     543    2.871088"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =================== 6. Criar predi√ß√µes ===================\n",
    "predictions = predict(svd, test_df, usercol=\"userID\", itemcol=\"itemID\")\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ca54b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.578591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.953589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.544043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.194905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3.911575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  itemID  prediction\n",
       "1       1       2    4.578591\n",
       "3       1       4    3.953589\n",
       "4       1       5    3.544043\n",
       "6       1       7    4.194905\n",
       "7       1       8    3.911575"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =================== 7. Criar predi√ß√µes com o treinamento para compara√ß√£o ===============\n",
    "\n",
    "# √â utilizado para avaliar as m√©tricas de ranking (MAP, NDCG, Precision@K, Recall@K).\n",
    "\n",
    "all_predictions = compute_ranking_predictions(\n",
    "    svd, train_df, usercol=\"userID\", itemcol=\"itemID\", remove_seen=True\n",
    ")\n",
    "all_predictions.head()\n",
    "\n",
    "# No bloco de c√≥digo seguinte √© feito uma compara√ß√£o entre as predi√ß√µes e as notas reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cd42a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t\t0.882922\n",
      "MAE:\t\t0.678920\n",
      "rsquared:\t0.286944\n",
      "exp var:\t0.287220\n",
      "----\n",
      "MAP:\t\t0.028756\n",
      "NDCG:\t\t0.065049\n",
      "Precision@K:\t0.054516\n",
      "Recall@K:\t0.021710\n"
     ]
    }
   ],
   "source": [
    "# =================== 7. Avalia√ß√£o das predi√ß√µes ====================\n",
    "\n",
    "# ‚ÄúO modelo acerta a nota que o usu√°rio deu para o filme?‚Äù\n",
    "eval_rmse = rmse(test_df, predictions)\n",
    "eval_mae = mae(test_df, predictions)\n",
    "eval_rsquared = rsquared(test_df, predictions)\n",
    "eval_exp_var = exp_var(test_df, predictions)\n",
    "\n",
    "# O modelo est√° colocando os filmes certos (que o usu√°rio realmente gosta) nas primeiras posi√ß√µes das recomenda√ß√µes?\n",
    "eval_map = map_at_k(test_df, all_predictions, col_prediction=\"prediction\", k=10)\n",
    "eval_ndcg = ndcg_at_k(test_df, all_predictions, col_prediction=\"prediction\", k=10)\n",
    "eval_precision = precision_at_k(\n",
    "    test_df, all_predictions, col_prediction=\"prediction\", k=10\n",
    ")\n",
    "eval_recall = recall_at_k(test_df, all_predictions, col_prediction=\"prediction\", k=10)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"RMSE:\\t\\t%f\" % eval_rmse,\n",
    "    \"MAE:\\t\\t%f\" % eval_mae,\n",
    "    \"rsquared:\\t%f\" % eval_rsquared,\n",
    "    \"exp var:\\t%f\" % eval_exp_var,\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "print(\n",
    "    \"MAP:\\t\\t%f\" % eval_map,\n",
    "    \"NDCG:\\t\\t%f\" % eval_ndcg,\n",
    "    \"Precision@K:\\t%f\" % eval_precision,\n",
    "    \"Recall@K:\\t%f\" % eval_recall,\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d892ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ TESTE DE FOLD-IN COM USU√ÅRIO REAL (COLD-START)\n",
      "Usu√°rio holdout: 249\n",
      "Este usu√°rio N√ÉO participou do treinamento do modelo.\n",
      "\n",
      "Total de avalia√ß√µes do usu√°rio: 1046\n",
      "\n",
      "üìä Divis√£o das avalia√ß√µes:\n",
      "  Avalia√ß√µes conhecidas (para fold-in): 836\n",
      "  Avalia√ß√µes ocultas (para valida√ß√£o): 210\n",
      "\n",
      "Exemplos de filmes que o usu√°rio avaliou (conhecidas):\n",
      "  ‚Ä¢ 50/50 (2011) (G√™nero: Comedy) ‚Üí Nota: 3.5\n",
      "  ‚Ä¢ A.I. Artificial Intelligence (2001) (G√™nero: Adventure) ‚Üí Nota: 3.5\n",
      "  ‚Ä¢ Star Trek (2009) (G√™nero: Action) ‚Üí Nota: 4.0\n",
      "  ‚Ä¢ Star Wars: Episode II - Attack of the Clones (2002) (G√™nero: Action) ‚Üí Nota: 3.5\n",
      "  ‚Ä¢ Hunt for the Wilderpeople (2016) (G√™nero: Adventure) ‚Üí Nota: 4.5\n",
      "\n",
      "Avalia√ß√µes conhecidas dispon√≠veis no trainset: 818/836\n",
      "‚úì Suficiente para fold-in!\n",
      "\n",
      "Mapeamento para inner IDs:\n",
      "  ‚úì Sucesso: 818\n",
      "\n",
      "Calculando vetor latente do usu√°rio via fold-in...\n",
      "‚úì Vetor latente calculado (dimens√£o: 200)\n",
      "‚úì Bias do usu√°rio: 0.088\n",
      "\n",
      "Gerando predi√ß√µes para todos os filmes do trainset...\n",
      "‚úì 8174 filmes candidatos (excluindo j√° avaliados)\n",
      "\n",
      "======================================================================\n",
      "üé¨ TOP-10 RECOMENDA√á√ïES PARA O USU√ÅRIO 249\n",
      "======================================================================\n",
      "\n",
      " 1. Yojimbo (1961)\n",
      "    G√™nero: Action | Nota estimada: 5.54\n",
      "\n",
      " 2. Muppet Christmas Carol, The (1992)\n",
      "    G√™nero: Children | Nota estimada: 5.00\n",
      "\n",
      " 3. Fight Club (1999)\n",
      "    G√™nero: Action | Nota estimada: 4.98\n",
      "\n",
      " 4. Star Wars: Episode IV - A New Hope (1977)\n",
      "    G√™nero: Action | Nota estimada: 4.96\n",
      "\n",
      " 5. Road Warrior, The (Mad Max 2) (1981)\n",
      "    G√™nero: Action | Nota estimada: 4.95\n",
      "\n",
      " 6. Graduate, The (1967)\n",
      "    G√™nero: Comedy | Nota estimada: 4.95\n",
      "\n",
      " 7. Maltese Falcon, The (1941)\n",
      "    G√™nero: Film-Noir | Nota estimada: 4.94\n",
      "\n",
      " 8. Escape from New York (1981)\n",
      "    G√™nero: Action | Nota estimada: 4.92\n",
      "\n",
      " 9. Grand Day Out with Wallace and Gromit, A (1989)\n",
      "    G√™nero: Adventure | Nota estimada: 4.86\n",
      "\n",
      "10. To Kill a Mockingbird (1962)\n",
      "    G√™nero: Drama | Nota estimada: 4.78\n",
      "\n",
      "======================================================================\n",
      "üìä AVALIA√á√ÉO DA QUALIDADE DAS RECOMENDA√á√ïES\n",
      "======================================================================\n",
      "\n",
      "Estat√≠sticas:\n",
      "  ‚Ä¢ Filmes recomendados: 10\n",
      "  ‚Ä¢ Filmes que o usu√°rio gostou nas avalia√ß√µes ocultas (nota ‚â• 4): 108\n",
      "\n",
      "M√©tricas de Performance:\n",
      "  ‚úì Acertos: 2 filme(s)\n",
      "  ‚Ä¢ Precision@10: 20.00%\n",
      "  ‚Ä¢ Recall@10: 1.85%\n",
      "  ‚Ä¢ F1-Score@10: 3.39%\n",
      "\n",
      "üéØ Filmes recomendados que o usu√°rio REALMENTE gostou:\n",
      "\n",
      "  ‚úì Star Wars: Episode IV - A New Hope (1977)\n",
      "    G√™nero: Action | Nota real: 5.0\n",
      "\n",
      "  ‚úì Fight Club (1999)\n",
      "    G√™nero: Action | Nota real: 5.0\n",
      "\n",
      "Distribui√ß√£o de notas nas avalia√ß√µes ocultas:\n",
      "  Nota 1.0: 3 filme(s)\n",
      "  Nota 2.0: 2 filme(s)\n",
      "  Nota 2.5: 8 filme(s)\n",
      "  Nota 3.0: 36 filme(s)\n",
      "  Nota 3.5: 53 filme(s)\n",
      "  Nota 4.0: 66 filme(s)\n",
      "  Nota 4.5: 24 filme(s)\n",
      "  Nota 5.0: 18 filme(s)\n",
      "\n",
      "======================================================================\n",
      "‚úì Fold-in conclu√≠do!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =================== 8. Fold-in com usu√°rio holdout (cold-start real) ===================\n",
    "import numpy as np\n",
    "\n",
    "MIN_AVALIACOES_PARA_FOLDIN = 5\n",
    "LAMBDA_REG = 0.1\n",
    "TOP_K = 10\n",
    "SPLIT_RATIO = 0.8  # 80% para fold-in, 20% para valida√ß√£o\n",
    "\n",
    "print(f\"üé¨ TESTE DE FOLD-IN COM USU√ÅRIO REAL (COLD-START)\")\n",
    "\n",
    "print(f\"Usu√°rio holdout: {HOLDOUT_USER_ID}\")\n",
    "print(f\"Este usu√°rio N√ÉO participou do treinamento do modelo.\\n\")\n",
    "\n",
    "# Verificar se temos dados do usu√°rio\n",
    "if len(user_holdout_data) == 0:\n",
    "    raise RuntimeError(f\"Nenhuma avalia√ß√£o encontrada para o usu√°rio {HOLDOUT_USER_ID}\")\n",
    "\n",
    "print(f\"Total de avalia√ß√µes do usu√°rio: {len(user_holdout_data)}\\n\")\n",
    "\n",
    "# --- PASSO 2: Dividir avalia√ß√µes em conhecidas e ocultas ---\n",
    "user_ratings_shuffled = user_holdout_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "split_point = int(len(user_ratings_shuffled) * SPLIT_RATIO)\n",
    "\n",
    "known_ratings = user_ratings_shuffled.iloc[:split_point].copy()\n",
    "hidden_ratings = user_ratings_shuffled.iloc[split_point:].copy()\n",
    "\n",
    "print(f\"üìä Divis√£o das avalia√ß√µes:\")\n",
    "print(f\"  Avalia√ß√µes conhecidas (para fold-in): {len(known_ratings)}\")\n",
    "print(f\"  Avalia√ß√µes ocultas (para valida√ß√£o): {len(hidden_ratings)}\\n\")\n",
    "\n",
    "# Mostrar algumas avalia√ß√µes conhecidas\n",
    "print(\"Exemplos de filmes que o usu√°rio avaliou (conhecidas):\")\n",
    "known_with_titles = known_ratings.merge(movies[[\"itemID\", \"title\", \"genres\"]], on=\"itemID\", how=\"left\")\n",
    "for idx, row in known_with_titles.head(5).iterrows():\n",
    "    first_genre = row[\"genres\"].split(\"|\")[0] if isinstance(row.get(\"genres\", None), str) else \"Desconhecido\"\n",
    "    print(f\"  ‚Ä¢ {row['title']} (G√™nero: {first_genre}) ‚Üí Nota: {row['rating']}\")\n",
    "print()\n",
    "\n",
    "# --- PASSO 3: Filtrar apenas filmes que est√£o no trainset ---\n",
    "train_raw_ids = [trainset.to_raw_iid(i) for i in range(trainset.n_items)]\n",
    "known_ratings_in_train = known_ratings[known_ratings[\"itemID\"].isin(train_raw_ids)].copy()\n",
    "\n",
    "print(f\"Avalia√ß√µes conhecidas dispon√≠veis no trainset: {len(known_ratings_in_train)}/{len(known_ratings)}\")\n",
    "\n",
    "if len(known_ratings_in_train) < MIN_AVALIACOES_PARA_FOLDIN:\n",
    "    print(f\"\\n‚ö†Ô∏è ERRO: Apenas {len(known_ratings_in_train)} avalia√ß√µes v√°lidas.\")\n",
    "    print(f\"Necess√°rio pelo menos {MIN_AVALIACOES_PARA_FOLDIN} para fold-in.\")\n",
    "    print(\"Sugest√µes:\")\n",
    "    print(\"  - Escolha um usu√°rio com mais avalia√ß√µes\")\n",
    "    print(\"  - Reduza MIN_AVALIACOES_PARA_FOLDIN\")\n",
    "    print(\"  - Aumente SPLIT_RATIO para ter mais avalia√ß√µes conhecidas\\n\")\n",
    "else:\n",
    "    print(f\"‚úì Suficiente para fold-in!\\n\")\n",
    "    \n",
    "    # --- PASSO 4: Aplicar fold-in com avalia√ß√µes conhecidas ---\n",
    "    avaliacoes = [(int(row[\"itemID\"]), float(row[\"rating\"])) \n",
    "                  for _, row in known_ratings_in_train.iterrows()]\n",
    "    \n",
    "    # Mapear avalia√ß√µes para inner ids\n",
    "    inner_ids = []\n",
    "    ratings = []\n",
    "    erros = 0\n",
    "    for raw_iid, r in avaliacoes:\n",
    "        try:\n",
    "            inner = trainset.to_inner_iid(raw_iid)\n",
    "            inner_ids.append(inner)\n",
    "            ratings.append(r)\n",
    "        except ValueError:\n",
    "            erros += 1\n",
    "            continue\n",
    "    \n",
    "    print(f\"Mapeamento para inner IDs:\")\n",
    "    print(f\"  ‚úì Sucesso: {len(inner_ids)}\")\n",
    "    if erros > 0:\n",
    "        print(f\"  ‚úó Falhas: {erros}\")\n",
    "    print()\n",
    "    \n",
    "    # Construir Q e y (res√≠duos)\n",
    "    mu = trainset.global_mean\n",
    "    k = svd.n_factors\n",
    "    Q = np.array([svd.qi[i] for i in inner_ids])\n",
    "    bi = np.array([svd.bi[i] for i in inner_ids])\n",
    "    y = np.array(ratings) - mu - bi\n",
    "    \n",
    "    print(\"Calculando vetor latente do usu√°rio via fold-in...\")\n",
    "    \n",
    "    # Resolver (Q^T Q + lambda I) p_u = Q^T y\n",
    "    A = Q.T.dot(Q) + LAMBDA_REG * np.eye(k)\n",
    "    b = Q.T.dot(y)\n",
    "    try:\n",
    "        p_u = np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        p_u = np.linalg.pinv(A).dot(b)\n",
    "    \n",
    "    # Estimar bias do usu√°rio\n",
    "    residuals = y - Q.dot(p_u)\n",
    "    b_u = float(np.mean(residuals)) if residuals.size > 0 else 0.0\n",
    "    \n",
    "    print(f\"‚úì Vetor latente calculado (dimens√£o: {len(p_u)})\")\n",
    "    print(f\"‚úì Bias do usu√°rio: {b_u:.3f}\\n\")\n",
    "    \n",
    "    # --- PASSO 5: Gerar recomenda√ß√µes ---\n",
    "    print(\"Gerando predi√ß√µes para todos os filmes do trainset...\")\n",
    "    preds = []\n",
    "    for inner_j in range(trainset.n_items):\n",
    "        qj = svd.qi[inner_j]\n",
    "        bj = svd.bi[inner_j]\n",
    "        est = mu + bj + b_u + p_u.dot(qj)\n",
    "        raw_j = trainset.to_raw_iid(inner_j)\n",
    "        preds.append((raw_j, est))\n",
    "    \n",
    "    # Remover itens que o usu√°rio j√° avaliou (conhecidas)\n",
    "    avaliados_raw = set([raw for raw, _ in avaliacoes])\n",
    "    preds = [p for p in preds if p[0] not in avaliados_raw]\n",
    "    \n",
    "    print(f\"‚úì {len(preds)} filmes candidatos (excluindo j√° avaliados)\\n\")\n",
    "    \n",
    "    # Ordenar e pegar top K\n",
    "    preds.sort(key=lambda x: x[1], reverse=True)\n",
    "    topk = preds[:TOP_K]\n",
    "    \n",
    "    # Exibir recomenda√ß√µes\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"üé¨ TOP-{TOP_K} RECOMENDA√á√ïES PARA O USU√ÅRIO {HOLDOUT_USER_ID}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    for i, (raw_j, est) in enumerate(topk, 1):\n",
    "        row = movies[movies[\"itemID\"] == raw_j]\n",
    "        if not row.empty:\n",
    "            title = row.iloc[0][\"title\"]\n",
    "            genres = row.iloc[0][\"genres\"] if \"genres\" in row.columns else \"\"\n",
    "            first_genre = genres.split(\"|\")[0] if isinstance(genres, str) and genres else \"Desconhecido\"\n",
    "            print(f\"{i:2d}. {title}\")\n",
    "            print(f\"    G√™nero: {first_genre} | Nota estimada: {est:.2f}\\n\")\n",
    "        else:\n",
    "            print(f\"{i:2d}. Item ID {raw_j} | Nota estimada: {est:.2f}\\n\")\n",
    "    \n",
    "    # --- PASSO 6: Avaliar qualidade das recomenda√ß√µes ---\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"üìä AVALIA√á√ÉO DA QUALIDADE DAS RECOMENDA√á√ïES\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Filmes recomendados (top K)\n",
    "    recommended_items = set([raw_j for raw_j, _ in topk])\n",
    "    \n",
    "    # Filmes que o usu√°rio realmente gostou nas avalia√ß√µes ocultas (nota >= 4)\n",
    "    hidden_liked = hidden_ratings[hidden_ratings[\"rating\"] >= 4.0].copy()\n",
    "    hidden_liked_set = set(hidden_liked[\"itemID\"].tolist())\n",
    "    \n",
    "    print(f\"Estat√≠sticas:\")\n",
    "    print(f\"  ‚Ä¢ Filmes recomendados: {len(recommended_items)}\")\n",
    "    print(f\"  ‚Ä¢ Filmes que o usu√°rio gostou nas avalia√ß√µes ocultas (nota ‚â• 4): {len(hidden_liked_set)}\\n\")\n",
    "    \n",
    "    # Verificar quantos filmes recomendados o usu√°rio realmente gostou\n",
    "    hits = recommended_items.intersection(hidden_liked_set)\n",
    "    \n",
    "    if len(hidden_liked_set) > 0:\n",
    "        precision = len(hits) / len(recommended_items) if len(recommended_items) > 0 else 0\n",
    "        recall = len(hits) / len(hidden_liked_set)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(f\"M√©tricas de Performance:\")\n",
    "        print(f\"  ‚úì Acertos: {len(hits)} filme(s)\")\n",
    "        print(f\"  ‚Ä¢ Precision@{TOP_K}: {precision:.2%}\")\n",
    "        print(f\"  ‚Ä¢ Recall@{TOP_K}: {recall:.2%}\")\n",
    "        print(f\"  ‚Ä¢ F1-Score@{TOP_K}: {f1:.2%}\\n\")\n",
    "        \n",
    "        if len(hits) > 0:\n",
    "            print(f\"üéØ Filmes recomendados que o usu√°rio REALMENTE gostou:\\n\")\n",
    "            for item_id in hits:\n",
    "                row = movies[movies[\"itemID\"] == item_id]\n",
    "                if not row.empty:\n",
    "                    title = row.iloc[0][\"title\"]\n",
    "                    actual_rating = hidden_ratings[hidden_ratings[\"itemID\"] == item_id][\"rating\"].values[0]\n",
    "                    genres = row.iloc[0][\"genres\"] if \"genres\" in row.columns else \"\"\n",
    "                    first_genre = genres.split(\"|\")[0] if isinstance(genres, str) and genres else \"Desconhecido\"\n",
    "                    print(f\"  ‚úì {title}\")\n",
    "                    print(f\"    G√™nero: {first_genre} | Nota real: {actual_rating}\\n\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Nenhum dos filmes recomendados est√° entre os que o usu√°rio gostou (ocultos).\\n\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è O usu√°rio n√£o tem filmes com nota alta (‚â•4) nas avalia√ß√µes ocultas.\\n\")\n",
    "    \n",
    "    # An√°lise adicional: distribui√ß√£o de notas nas avalia√ß√µes ocultas\n",
    "    print(f\"Distribui√ß√£o de notas nas avalia√ß√µes ocultas:\")\n",
    "    dist = hidden_ratings[\"rating\"].value_counts().sort_index()\n",
    "    for nota, count in dist.items():\n",
    "        print(f\"  Nota {nota}: {count} filme(s)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úì Fold-in conclu√≠do!\")\n",
    "    print(f\"{'='*70}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenci_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
