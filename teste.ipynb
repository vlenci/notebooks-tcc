{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate lenci_enviroment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8090ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import surprise\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    rmse,\n",
    "    mae,\n",
    "    rsquared,\n",
    "    exp_var,\n",
    "    map_at_k,\n",
    "    ndcg_at_k,\n",
    "    precision_at_k,\n",
    "    recall_at_k,\n",
    "    get_top_k_items,\n",
    ")\n",
    "from recommenders.models.surprise.surprise_utils import (\n",
    "    predict,\n",
    "    compute_ranking_predictions,\n",
    ")\n",
    "from recommenders.utils.notebook_utils import store_metadata\n",
    "\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Surprise version: {surprise.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4ea92ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       1       17     4.0\n",
      "1       1       25     1.0\n",
      "2       1       29     2.0\n",
      "3       1       30     5.0\n",
      "4       1       32     5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Caminho do arquivo local do MovieLens 100k\n",
    "file_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-32m\\\\ratings.csv\"  # ajuste para onde voc√™ extraiu o dataset\n",
    "\n",
    "# Ler o arquivo com pandas\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "\n",
    "# Selecionar apenas as colunas necess√°rias\n",
    "df = df[[\"userId\", \"movieId\", \"rating\"]]\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(df.head())\n",
    "\n",
    "# Criar Dataset do Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df, reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5392c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "\n",
    "# 1Ô∏è‚É£ Dividir os dados em treino e teste (75% treino, 25% teste)\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# 2Ô∏è‚É£ Criar o modelo SVD\n",
    "svd = SVD(\n",
    "    n_factors=200,   # dimens√£o dos vetores latentes\n",
    "    n_epochs=30,     # n√∫mero de itera√ß√µes do SGD\n",
    "    random_state=42,\n",
    "    verbose=True     # imprime progresso do treino\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Treinar o modelo\n",
    "svd.fit(trainset)\n",
    "\n",
    "# 4Ô∏è‚É£ Fazer previs√µes no conjunto de teste\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# 5Ô∏è‚É£ Avaliar o modelo usando RMSE e MAE\n",
    "rmse_val = accuracy.rmse(predictions)\n",
    "mae_val = accuracy.mae(predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse_val}\")\n",
    "print(f\"MAE: {mae_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713c218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Fun√ß√£o auxiliar para pegar os Top-K itens recomendados\n",
    "def get_top_n(predictions, n=10):\n",
    "    # Dicion√°rio para armazenar as recomenda√ß√µes por usu√°rio\n",
    "    user_recommendations = defaultdict(list)\n",
    "\n",
    "    # Organiza as previs√µes por usu√°rio\n",
    "    for user_id, movie_id, true_rating, predicted_rating, _ in predictions:\n",
    "        user_recommendations[user_id].append((movie_id, predicted_rating))\n",
    "\n",
    "    # Ordena as predi√ß√µes por nota estimada e pega o Top-N\n",
    "    for user_id, movie_ratings in user_recommendations.items():\n",
    "        movie_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        user_recommendations[user_id] = movie_ratings[:n]\n",
    "\n",
    "    return user_recommendations\n",
    "\n",
    "\n",
    "# ‚ö° Fazer previs√µes em todos os pares usu√°rio-filme que n√£o estavam no treino\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Gera previs√µes para todos os pares usu√°rio-filme n√£o vistos no treino\n",
    "all_predictions = svd.test(trainset.build_anti_testset())\n",
    "\n",
    "# Pega as top-10 recomenda√ß√µes para cada usu√°rio\n",
    "top_recommendations = get_top_n(all_predictions, n=10)\n",
    "\n",
    "# Exibir recomenda√ß√µes para os 5 primeiros usu√°rios\n",
    "for user_id, recommended_movies in list(top_recommendations.items())[:5]:\n",
    "    print(f\"\\nUsu√°rio {user_id} - Recomenda√ß√µes:\")\n",
    "    for movie_id, predicted_rating in recommended_movies:\n",
    "        print(f\"  Filme {movie_id} com nota estimada {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8daccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fede259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 1. Carregar dataset =========\n",
    "file_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\ratings.csv\"\n",
    "movies_path = \"C:\\\\Users\\\\vlenc\\\\OneDrive\\\\Documentos\\\\ml-latest-small\\\\movies.csv\"  # precisa desse para t√≠tulos\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\",\")\n",
    "movies = pd.read_csv(movies_path, sep=\",\")\n",
    "\n",
    "# Vamos trabalhar s√≥ com as colunas necess√°rias\n",
    "df = df[[\"userId\", \"movieId\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e42e2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responda 0 (n√£o assistiu), 1 (n√£o gostou), 2 (gostou).\n",
      "Ap√≥s 10 avalia√ß√µes v√°lidas (1 ou 2), vamos treinar o modelo.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Coletamos 10 avalia√ß√µes v√°lidas do usu√°rio!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========= 2. Simula√ß√£o de avalia√ß√µes do usu√°rio =========\n",
    "import numpy as np\n",
    "\n",
    "avaliacoes_usuario = []  # guarda (userId, movieId, rating)\n",
    "print(\"Responda 0 (n√£o assistiu), 1 (n√£o gostou), 2 (gostou).\")\n",
    "print(\"Ap√≥s 10 avalia√ß√µes v√°lidas (1 ou 2), vamos treinar o modelo.\\n\")\n",
    "\n",
    "# Embaralhar os filmes e calcular peso por popularidade\n",
    "movie_counts = movies.groupby(\"movieId\").size()\n",
    "movies[\"weight\"] = movies[\"movieId\"].map(movie_counts)\n",
    "\n",
    "contador_validas = 0\n",
    "movies_restantes = movies.copy()\n",
    "\n",
    "while contador_validas < 10 and len(movies_restantes) > 0:\n",
    "    # Seleciona filme aleat√≥rio ponderado\n",
    "    filme = movies_restantes.sample(n=1, weights=\"weight\").iloc[0]\n",
    "    movie_id = filme[\"movieId\"]\n",
    "    title = filme[\"title\"]\n",
    "\n",
    "    resposta = input(f\"Voc√™ assistiu '{title}'? (0=N√£o, 1=N√£o gostou, 2=Gostou): \")\n",
    "\n",
    "    if resposta not in [\"0\", \"1\", \"2\"]:\n",
    "        print(\"Resposta inv√°lida, tente novamente.\")\n",
    "        continue\n",
    "\n",
    "    resposta = int(resposta)\n",
    "\n",
    "    if resposta in [1, 2]:\n",
    "        avaliacoes_usuario.append((9999, movie_id, resposta))  # userId fixo=9999\n",
    "        contador_validas += 1\n",
    "\n",
    "    # Remove o filme da lista para n√£o aparecer novamente\n",
    "    movies_restantes = movies_restantes[movies_restantes[\"movieId\"] != movie_id]\n",
    "\n",
    "print(\"\\n‚úÖ Coletamos 10 avalia√ß√µes v√°lidas do usu√°rio!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01e38f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= 3. Preparar dataset para Surprise =========\n",
    "# Criar novo DF juntando dataset original + usu√°rio novo\n",
    "df_usuario = pd.DataFrame(avaliacoes_usuario, columns=[\"userId\", \"movieId\", \"rating\"])\n",
    "df_final = pd.concat([df, df_usuario], ignore_index=True)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_final[[\"userId\", \"movieId\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fc4078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x16b5043e520>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========= 4. Treinar modelo =========\n",
    "trainset = data.build_full_trainset()\n",
    "svd = SVD(n_factors=1000, n_epochs=30, random_state=42, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9299fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Recomenda√ß√µes para voc√™:\n",
      "- Upside Down: The Creation Records Story (2010) (nota estimada 4.24)\n",
      "- Blue Velvet (1986) (nota estimada 4.20)\n",
      "- Three Billboards Outside Ebbing, Missouri (2017) (nota estimada 4.15)\n",
      "- Once Upon a Time in the West (C'era una volta il West) (1968) (nota estimada 4.15)\n",
      "- Uncle Buck (1989) (nota estimada 4.10)\n",
      "- Reservoir Dogs (1992) (nota estimada 4.10)\n",
      "- Eyes of Tammy Faye, The (2000) (nota estimada 4.09)\n",
      "- Chaser, The (Chugyeogja) (2008) (nota estimada 4.05)\n",
      "- Call Me by Your Name (2017) (nota estimada 4.04)\n",
      "- Ogre, The (Unhold, Der) (1996) (nota estimada 4.03)\n"
     ]
    }
   ],
   "source": [
    "# ========= 5. Gerar recomenda√ß√µes =========\n",
    "# Criar anti-testset s√≥ para o usu√°rio novo\n",
    "anti_testset = []\n",
    "for movie_id in movies[\"movieId\"]:\n",
    "    if movie_id not in df_usuario[\"movieId\"].values:  # s√≥ filmes n√£o avaliados\n",
    "        anti_testset.append((9999, movie_id, 0))  # rating dummy\n",
    "\n",
    "predictions = svd.test(anti_testset)\n",
    "\n",
    "# Ordenar por nota estimada\n",
    "predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "# Pegar top 10\n",
    "top_10 = predictions[:10]\n",
    "\n",
    "print(\"\\nüé¨ Recomenda√ß√µes para voc√™:\")\n",
    "for pred in top_10:\n",
    "    movie_id = pred.iid\n",
    "    title = movies[movies[\"movieId\"] == int(movie_id)][\"title\"].values[0]\n",
    "    print(f\"- {title} (nota estimada {pred.est:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenci_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
